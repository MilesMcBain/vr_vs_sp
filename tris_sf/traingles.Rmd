---
title: "Spatial to VR with R"
author: "Miles McBain"
output: html_document
---

```{r}
library(sf)
library(raster)
library(RTriangle)
library(tidyverse)
nc <- read_sf(system.file("shape/nc.shp", package="sf"))
```

# Some Fake Data

From : https://cran.r-project.org/web/packages/sf/vignettes/sf1.html

```{r}
p1 <- rbind(c(0,0), c(1,0), c(1,1), c(0,1), c(0,0)) # block
p2 <- rbind(c(0.25,0.25), c(0.75,0.25), c(0.75,0.75), c(0.25,0.75), c(0.25,0.25)) # hole
p3 <- rbind(c(0,1), c(1,1), c(1,2), c(0,2), c(0,1)) # block
p4 <- rbind(c(0.25,1.25), c(0.75,1.25), c(0.75,1.75), c(0.25,1.75), c(0.25,1.25)) # hole
p5 <- rbind(c(2,1.1), c(3,1.1), c(3,2), c(2,2), c(2, 1.1)) # mini-block
p6 <- rbind(c(2.25,1.25), c(2.75,1.25), c(2.75,1.75), c(2.25,1.75), c(2.25,1.25)) # hole
p7 <- rbind(c(2,0), c(3,0), c(3,1), c(2,1), c(2,0)) # block

mpol_1 <- st_multipolygon(list(list(p1,p2), list(p3,p4)))
mpol_2 <- st_multipolygon(list(list(p5,p6), list(p7)))
my_sf <- st_sfc(mpol_1, 
                mpol_2)
```

# Plot the fake data

```{r}
plot(my_sf)
```

# A function to Triangulate

```{r}     
sf_to_tri_mesh <- function(a_mulitpoly_sf, n_tris = NULL){
  
  if(!is(a_mulitpoly_sf, "sfc_MULTIPOLYGON")){
    stop("sf_to_tri_mesh can only work with sf geometry containing a single MULTIPOLYGON") 
  } 
  if(length(a_mulitpoly_sf) != 1){
    stop("Argument geomerty contained more than 1 MULTIPOLYGON. Use st_union() or st_combine()") 
  }

    # For RTRiangle we need:
    # P - A list of all unique vertices
    # PB - A vector the same length as P indicating if vertex is on boundary
    # PA - not required but maybe be useful for rastersation. Probably want explicit control.
    # S - a list of segments need boundary segments and hole segments
    #     Uses verex indicie in P.
    # SB - a vector the same length as S indicating boundaries
    # H - a vector of holes points in segments # For RTRiangle we need:
    # P - A list of all unique vertices
    # PB - A vector the same length as P indicating if vertex is on boundary
    # PA - not required but maybe be useful for rastersation. Probably want explicit control.
    # S - a list of segments need boundary segments and hole segments
    #     Uses verex indicie in P.
    # SB - a vector the same length as S indicating boundaries
    # H - a vector of holes points in segments

  island_list <-
    map(a_mulitpoly_sf[[1]], ~.[1]) %>% 
    flatten() %>%
    map(as_tibble) %>%
    map(~mutate(., type = "island"))
  
  hole_list <-
    map(a_mulitpoly_sf[[1]], ~.[-1]) %>%
    flatten() %>%
    map(as_tibble) %>%
    map(~mutate(., type = "hole"))
  
  all_polys_list <- c(island_list, hole_list)
  all_polys_list <-
    pmap(list(all_polys_list, seq_along(all_polys_list)),
      function(polygon_df, group_id){
        mutate(polygon_df, group = group_id)
      }
    )

  vertex_df <- 
    bind_rows(all_polys_list) %>%
    rename(x = V1, y = V2)
  
  unique_vertices <- 
    vertex_df %>%
    select(x, y) %>%
    unique() %>%
    mutate(id = seq_along(x))
  
  # Df containing P, PB, S, SB, where PB = SB
  segment_boundary_df <- 
    left_join(vertex_df, unique_vertices, by = c("x","y")) %>%
    group_by(group) %>%
    mutate(segment_start = id,
           segment_end = lead(id),
           boundary_ind = if_else(type == "island", 1, 0)) %>%
    ungroup()
  
  # Have NAs in segments, fine but before we drop those we need the closed 
  # vertex rings in x,y to calculate some centroids. 
  hole_centroids <-
    segment_boundary_df %>%
    filter(type == "hole") %>%
    group_by(group) %>%
    summarise(centroid = list( 
      st_centroid(st_polygon( list( as.matrix(cbind(x,y)) ) )) )) %>%
    pull(centroid) %>%
    map(as.matrix) %>%
    do.call(rbind, .)

  # Drop segments that contain NAs
  segment_boundary_df <- drop_na(segment_boundary_df)

  vertex_boundary_df <-
    segment_boundary_df %>%
    select(x,y,boundary_ind) %>%
    unique()  

  rtri_args <- 
    list(
      P = vertex_boundary_df %>%
         select(x, y) %>%
         as.matrix(),   
      PB = pull(vertex_boundary_df, boundary_ind),
      S = segment_boundary_df %>%
          select(segment_start, segment_end) %>%
          as.matrix(),
      SB = pull(segment_boundary_df, boundary_ind),
      H = if(is.null(hole_centroids)) NA else hole_centroids
      )
  
  # Calculate the triangle area to give approx n_tris
  if (!is.null(n_tris)){
    bbox <- st_bbox(a_mulitpoly_sf)
    area <- (bbox[3] - bbox[1]) * (bbox[4] - bbox[2])
    tri_area <- area/n_tris
  } else {
    tri_area <- NULL
  }


  rt_pslg <- do.call(RTriangle::pslg, rtri_args)
  
  rt_triangles <- RTriangle::triangulate(rt_pslg, a = tri_area)
}

# Triangulation Results

unioned_df <-  
  my_sf %>%
  st_union()

nc_unioned_df <-
  nc %>%
  st_geometry() %>%
  st_combine()

plot(sf_to_tri_mesh(unioned_df, n_tris = 1000))
    

plot(sf_to_tri_mesh(nc_unioned_df, n_tris = 1000))

```  

# Alternatives


```{r}
library(sfdct)
ct_triangulate(my_sf %>% st_union() %>% st_geometry(), a = 0.008 )[[1]] %>% plot(col = "white")
nc_triangles <- ct_triangulate(nc)
plot(st_geometry(nc_triangles),   col = viridisLite::viridis(nrow(nc_triangles)))
```

The same underlying algorithm. The issue is that these are not in a 3D ready format. The default output is actually better.

# Making the mesh 3d 
The `elevatr` package can fetch elevation data. At present the download speeds for it's raster tile sources are quite slow. 
They're faster for zoomed-out tiles,
but these are not great for 'human scale' VR. There are a lot of public datasets available, but none with R package interfaces.
The standard also seems to be you need to make an account to download these. I have found 1m and 5m LIDAR and elevation model data
for sites of interest from my local state [geoscience body](http://qldspatial.information.qld.gov.au/catalogue/custom/index.page). 

Other good options: 

  * [British Oceanographic Data Centre](https://www.bodc.ac.uk/data/hosted_data_systems/gebco_gridded_bathymetry_data/)
  * [Open Topography](http://opentopo.sdsc.edu/datasets)
  * More [here](http://gisgeography.com/free-global-dem-data-sources/).

Here I've used the an extract of the BDOC GEBCO grid, which has a permissive license. The extract contains elevation data at a 30m resolution for the United States. 

```{r}
library(sf)
library(ncdf4)
library(raster)

if(!file.exists("./data/GEBCO_2014_2D_-140.1818_22.6909_-50.9455_58.2545.nc")) {
  source("./data/fetch_data_file_12J-285aSC4taBmGVr6F0xZpO_H5pBNpo.R")
}
gebco_raster <- raster("./data/GEBCO_2014_2D_-140.1818_22.6909_-50.9455_58.2545.nc")
nc <- st_transform(nc, crs(gebco_raster)@projargs) # Transform our polygons to same CRS as raster

# Sanity check. Do these overlap?
plot(gebco_raster)
st_transform(nc, "+proj=longlat +datum=WGS84") %>%
as('Spatial') %>%
plot(add = TRUE)
```

# Making the Mesh

Choose a sensible number of triangles for `n_tris`, it's approximate. 3000 sounds good.

Now we traingulate and transform the triangulation vertices to metres, so they are on the same scale as the elevation data from the GEBCO raster.

```{r}
nc_trimesh <- 
  nc %>%
  st_geometry() %>%
  st_union() %>%
  sf_to_tri_mesh(1000)

z <- raster::extract(gebco_raster, nc_trimesh$P[,1:2])

# transform to metres
nc_verts <- st_sfc(st_multipoint(nc_trimesh$P, dim = "XY"))
st_crs(nc_verts)  <- st_crs(nc)
nc_verts <- st_transform(nc_verts, crs = "+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs")
nc_trimesh$P <- cbind(as(nc_verts[[1]], 'matrix'), z)

library(rgl)
  wire3d(
    tmesh3d(vertices = t(asHomogeneous(nc_trimesh$P)), indices = array(t(nc_trimesh$T)))
  )
rglwidget()
# Okay but now from this perspective it is basically completely flat.
```
