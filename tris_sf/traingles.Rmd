---
title: "Spatial to VR with R"
author: "Miles McBain"
output: html_document
---

```{r}
library(sf)
library(raster)
library(tidyverse)
library(RTriangle)
nc <- read_sf(system.file("shape/nc.shp", package="sf"))
```

# Some Fake Data

From : https://cran.r-project.org/web/packages/sf/vignettes/sf1.html

```{r}
p1 <- rbind(c(0,0), c(1,0), c(1,1), c(0,1), c(0,0)) # block
p2 <- rbind(c(0.25,0.25), c(0.75,0.25), c(0.75,0.75), c(0.25,0.75), c(0.25,0.25)) # hole
p3 <- rbind(c(0,1), c(1,1), c(1,2), c(0,2), c(0,1)) # block
p4 <- rbind(c(0.25,1.25), c(0.75,1.25), c(0.75,1.75), c(0.25,1.75), c(0.25,1.25)) # hole
p5 <- rbind(c(2,1.1), c(3,1.1), c(3,2), c(2,2), c(2, 1.1)) # mini-block
p6 <- rbind(c(2.25,1.25), c(2.75,1.25), c(2.75,1.75), c(2.25,1.75), c(2.25,1.25)) # hole
p7 <- rbind(c(2,0), c(3,0), c(3,1), c(2,1), c(2,0)) # block

mpol_1 <- st_multipolygon(list(list(p1,p2), list(p3,p4)))
mpol_2 <- st_multipolygon(list(list(p5,p6), list(p7)))
my_sf <- st_sfc(mpol_1, 
                mpol_2)
```

# Plot the fake data

```{r}
plot(my_sf)
```

# A function to Triangulate

```{r}     
sf_to_tri_mesh <- function(a_mulitpoly_sf, tri_area = NULL){
  
  if(!is(a_mulitpoly_sf, "sfc_MULTIPOLYGON")){
    stop("sf_to_tri_mesh can only work with sf geometry containing a single MULTIPOLYGON") 
  } 
  if(length(a_mulitpoly_sf) != 1){
    stop("Argument geomerty contained more than 1 MULTIPOLYGON. Use st_union() or st_combine()") 
  }

    # For RTRiangle we need:
    # P - A list of all unique vertices
    # PB - A vector the same length as P indicating if vertex is on boundary
    # PA - not required but maybe be useful for rastersation. Probably want explicit control.
    # S - a list of segments need boundary segments and hole segments
    #     Uses verex indicie in P.
    # SB - a vector the same length as S indicating boundaries
    # H - a vector of holes points in segments # For RTRiangle we need:
    # P - A list of all unique vertices
    # PB - A vector the same length as P indicating if vertex is on boundary
    # PA - not required but maybe be useful for rastersation. Probably want explicit control.
    # S - a list of segments need boundary segments and hole segments
    #     Uses verex indicie in P.
    # SB - a vector the same length as S indicating boundaries
    # H - a vector of holes points in segments

  island_list <-
    map(a_mulitpoly_sf[[1]], ~.[1]) %>% 
    flatten() %>%
    map(as_tibble) %>%
    map(~mutate(., type = "island"))
  
  hole_list <-
    map(a_mulitpoly_sf[[1]], ~.[-1]) %>%
    flatten() %>%
    map(as_tibble) %>%
    map(~mutate(., type = "hole"))
  
  all_polys_list <- c(island_list, hole_list)
  all_polys_list <-
    pmap(list(all_polys_list, seq_along(all_polys_list)),
      function(polygon_df, group_id){
        mutate(polygon_df, group = group_id)
      }
    )

  vertex_df <- 
    bind_rows(all_polys_list) %>%
    rename(x = V1, y = V2)
  
  unique_vertices <- 
    vertex_df %>%
    select(x, y) %>%
    unique() %>%
    mutate(id = seq_along(x))
  
  # Df containing P, PB, S, SB, where PB = SB
  segment_boundary_df <- 
    left_join(vertex_df, unique_vertices, by = c("x","y")) %>%
    group_by(group) %>%
    mutate(segment_start = id,
           segment_end = lead(id),
           boundary_ind = if_else(type == "island", 1, 0)) %>%
    ungroup()
  
  # Have NAs in segments, fine but before we drop those we need the closed 
  # vertex rings in x,y to calculate some centroids. 
  hole_centroids <-
    segment_boundary_df %>%
    filter(type == "hole") %>%
    group_by(group) %>%
    summarise(centroid = list( 
      st_centroid(st_polygon( list( as.matrix(cbind(x,y)) ) )) )) %>%
    pull(centroid) %>%
    map(as.matrix) %>%
    do.call(rbind, .)

  # Drop segments that contain NAs
  segment_boundary_df <- drop_na(segment_boundary_df)

  vertex_boundary_df <-
    segment_boundary_df %>%
    select(x,y,boundary_ind) %>%
    unique()  

  rtri_args <- 
    list(
      P = vertex_boundary_df %>%
         select(x, y) %>%
         as.matrix(),   
      PB = pull(vertex_boundary_df, boundary_ind),
      S = segment_boundary_df %>%
          select(segment_start, segment_end) %>%
          as.matrix(),
      SB = pull(segment_boundary_df, boundary_ind),
      H = if(is.null(hole_centroids)) NA else hole_centroids
      )

  rt_pslg <- do.call(RTriangle::pslg, rtri_args)

  rt_triangles <- RTriangle::triangulate(rt_pslg, a = tri_area)
}

# Triangulation Results

unioned_df <-  
  my_sf %>%
  st_union()

nc_unioned_df <-
  nc %>%
  st_geometry() %>%
  st_combine()

plot(sf_to_tri_mesh(unioned_df, 0.008))
    

plot(sf_to_tri_mesh(nc_unioned_df))

```  

# Alternatives


```{r}
library(sfdct)
ct_triangulate(my_sf %>% st_union() %>% st_geometry(), a = 0.008 )[[1]] %>% plot(col = "white")
nc_triangles <- ct_triangulate(nc)
plot(st_geometry(nc_triangles),   col = viridisLite::viridis(nrow(nc_triangles)))
```

The same underlying algorithm. The issue is that these are not in a 3D ready format. The default output is actually better.

# Making the mesh 3d 
The `elevatr` package can fetch elevation data. At present the download speeds for it's raster tile sources are quite slow. 
They're faster for zoomed-out tiles,
but these are not great for 'human scale' VR. There are a lot of public datasets available, but none with R package interfaces.
The standard also seems to be you need to make an account to download these. I have found 1m and 5m LIDAR and elevation model data
for sites of interest from my local state [geoscience body](http://qldspatial.information.qld.gov.au/catalogue/custom/index.page). 

Other good options: 

  * [British Oceanographic Data Centre](https://www.bodc.ac.uk/data/hosted_data_systems/gebco_gridded_bathymetry_data/)
  * [Open Topography](http://opentopo.sdsc.edu/datasets)
  * More [here](http://gisgeography.com/free-global-dem-data-sources/).

Here I've used the an extract of the BDOC GEBCO grid, which has a permissive license. The extract contains elevation data at a 30m resolution for the United States. 

```{r}
library(sf)
library(ncdf4)
library(raster)
#bodc_data_file <- "./data/GEBCO_2014_2D_-140.1818_22.6909_-50.9455_58.2545.nc"
#bodc_data <- nc_open(bodc_data_file)
#us_lat <- ncvar_get(bodc_data, "lat")
#us_lon <- ncvar_get(bodc_data, "lon")
#us_elev <- ncvar_get(bodc_data, "elevation")

#library(raster)
#dim(us_elev)
#dim(us_lat)
#dim(us_lon)

# make a raster
#elev_raster <- raster(ncol = dim(us_lon),
#                      nrow = dim(us_lat),
#                      xmn = min(us_lon),
#                      xmx = max(us_lon),
#                      ymn = min(us_lat),
#                      ymx = max(us_lat))

#values(elev_raster) <- t(us_elev)[1:ncell(elev_raster)]

ot_raster <- raster("./data/output_alos.tif")

# looks whacked!


nc_trimesh <- 
  nc %>%
  st_geometry() %>%
  st_union() %>%
  sf_to_tri_mesh(0.08)
```

```{r}
z <- raster::extract(ot_raster, nc_trimesh$P)/1000
nc_trimesh$P <- cbind(nc_trimesh$P, z) 


library(rgl)
wire3d(
  tmesh3d(vertices = t(asHomogeneous(nc_trimesh$P)), indices = array(t(nc_trimesh$T)))
)
# Okay but got some shitty values.
```